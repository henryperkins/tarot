# Azure OpenAI gpt-4o-mini-tts Integration

## Overview

Mystic Tarot now uses Azure OpenAI's **gpt-4o-mini-tts** model for context-aware, mystical voice narration. This implementation leverages the model's unique **steerable instructions** feature to adapt tone, pacing, and delivery style based on the reading context.

---

## Key Features

### âœ¨ **Steerable Instructions**
- Context-aware tone adjustment (card reveals vs full readings)
- Mystical, contemplative pacing with natural pauses
- Trauma-informed, gentle delivery style

### ğŸ™ï¸ **Voice Selection**
- Default: **nova** (warm, mystical)
- Available: shimmer, alloy, echo, fable, onyx
- Easily configurable per request

### ğŸ’¾ **Intelligent Caching**
- localStorage-based audio caching
- 7-day cache expiration
- Automatic eviction (keeps 50 most recent)
- Dramatically reduces API costs for repeated content

### ğŸ¯ **Context-Specific Narration**
- **card-reveal**: Brief, reverent single-card announcements
- **full-reading**: Contemplative, flowing complete readings
- **synthesis**: Storytelling cadence for theme integration
- **question**: Warm, inviting question acknowledgment
- **reflection**: Validating, supportive reflection echoing

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Context-Aware TTS Pipeline              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Frontend: TarotReading.jsx
  â†“ speak(text, 'card-reveal')
  â†“ speak(personalReading, 'full-reading')

Audio Library: src/lib/audio.js
  â”œâ”€ generateCacheKey(text, context, voice)
  â”œâ”€ getCachedAudio(key)  â†’ Cache hit? Return
  â”‚                       â†’ Cache miss? Continue â†“
  â”œâ”€ fetch('/api/tts', { text, context, voice })
  â””â”€ cacheAudio(key, audio)

Backend: functions/api/tts.js
  â”œâ”€ INSTRUCTION_TEMPLATES[context]
  â”œâ”€ buildPayload({
  â”‚    voice: 'nova',
  â”‚    input: text,
  â”‚    speed: 0.95,              â† Slower for contemplation
  â”‚    instructions: template     â† KEY FEATURE
  â”‚  })
  â””â”€ Azure OpenAI gpt-4o-mini-tts

Azure Response: audio/mpeg (base64 data URI)
```

---

## Implementation Details

### Backend (`functions/api/tts.js`)

#### **Instruction Templates**

```javascript
const INSTRUCTION_TEMPLATES = {
  'card-reveal': `Speak gently and mystically, as a tarot reader revealing
    a single card with reverence. Use a slightly slower pace with brief pauses
    after the card name and orientation. Convey wisdom and contemplation.`,

  'full-reading': `Speak as a wise, compassionate tarot reader sharing a complete
    reading. Use a thoughtful, contemplative tone with natural pauses between card
    descriptions. Speak slowly and deliberately, as if sitting across from the querent.
    Maintain a gentle, trauma-informed presence throughout.`,

  'synthesis': `Speak as a tarot reader weaving together the threads of a reading
    into cohesive guidance. Use a flowing, storytelling cadence. Pause briefly
    between major insights to allow integration. Convey wisdom and warmth,
    emphasizing agency and empowerment.`,

  // ... additional contexts
};
```

#### **API Payload**

```javascript
{
  model: "gpt-4o-mini-tts",
  voice: "nova",                    // Warm, mystical voice
  input: "The Fool reversed...",
  response_format: "mp3",
  speed: 0.95,                      // Slightly slower for contemplation
  instructions: INSTRUCTION_TEMPLATES[context]  // â† STEERABLE TONE
}
```

#### **Environment Variables Required**

```bash
AZURE_OPENAI_ENDPOINT=https://YOUR-RESOURCE.openai.azure.com
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_GPT_AUDIO_MINI_DEPLOYMENT=gpt-4o-mini-tts  # or tts-1-hd
AZURE_OPENAI_API_VERSION=2025-04-01-preview  # Optional, defaults
AZURE_OPENAI_GPT_AUDIO_MINI_FORMAT=mp3      # Optional, defaults
```

#### **Model Compatibility**

The implementation automatically detects which TTS model you're using and adapts the API request accordingly:

| Model | Steerable Instructions | Speed Control | Voice Selection | Best For |
|-------|------------------------|---------------|-----------------|----------|
| **gpt-4o-mini-tts** â­ | âœ… YES | âœ… YES | âœ… YES | Context-aware mystical narration |
| **tts-1-hd** | âŒ NO | âœ… YES | âœ… YES | High-quality voice without instructions |
| **tts-1** | âŒ NO | âœ… YES | âœ… YES | Standard quality, faster generation |

**Auto-Detection Logic:**
- If deployment name includes `gpt-4o`, `mini-tts`, or `audio-preview` â†’ Instructions are included âœ…
- Otherwise (tts-1/tts-1-hd) â†’ Instructions are omitted to avoid API errors âŒ

**Recommendation:** Use **gpt-4o-mini-tts** for the full context-aware, contemplative tarot narration experience with steerable instructions. Fall back to **tts-1-hd** if you only need high-quality voice without custom delivery styles.

---

### Frontend (`src/lib/audio.js`)

#### **Enhanced speakText Function**

```javascript
export async function speakText({
  text,
  enabled,
  context = 'default',    // NEW: Context parameter
  voice = 'nova'          // NEW: Voice selection
}) {
  // 1. Check cache first
  const cacheKey = generateCacheKey(text, context, voice);
  const cachedAudio = getCachedAudio(cacheKey);

  if (cachedAudio) {
    // Play cached audio (instant, no API call!)
    playAudio(cachedAudio);
  } else {
    // 2. Fetch from API with context and voice
    const response = await fetch('/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text, context, voice })
    });

    const { audio } = await response.json();

    // 3. Cache for future use
    cacheAudio(cacheKey, audio);

    // 4. Play
    playAudio(audio);
  }
}
```

#### **Caching Strategy**

- **Cache key**: Hash of `${text}|${context}|${voice}`
- **Storage**: localStorage with JSON serialization
- **Expiration**: 7 days (auto-purge stale entries)
- **Eviction**: When 50 items reached, remove oldest 10
- **Size**: Data URIs are base64, ~1.5MB per 1-minute audio

**Benefits:**
- Same card reveal = instant playback (no API cost)
- Offline capability for cached content
- Significant cost reduction for repeated readings

---

### Frontend Integration (`src/TarotReading.jsx`)

#### **Usage Examples**

```javascript
// Card reveal (brief, reverent)
void speak(shortLineForCard(card, position), 'card-reveal');

// Full reading (contemplative, flowing)
void speak(personalReading, 'full-reading');

// Future: Synthesis section
void speak(synthesisText, 'synthesis');

// Future: User's question
void speak(userQuestion, 'question');
```

---

## Cost Analysis

### Pricing Structure

- **gpt-4o-mini-tts**: $0.60/1M input tokens + ~$0.015/minute output
- **Effective cost**: ~$0.015 per minute of generated audio

### Sample Costs

| Content Type | Length | Text Tokens | Audio Duration | Cost |
|--------------|--------|-------------|----------------|------|
| Card reveal | "The Fool reversed - recklessness..." | ~30 tokens | ~15 sec | ~$0.004 |
| Full reading (3-card) | ~500 words | ~650 tokens | ~3 min | ~$0.045 |
| Full reading (Celtic Cross) | ~1000 words | ~1300 tokens | ~6 min | ~$0.090 |

### Cache Impact

Without caching:
- User reveals 10 cards sequentially = 10 API calls = $0.040
- User listens to same reading twice = 2 API calls = $0.090

With caching:
- First reveal: $0.004 per unique card
- Subsequent reveals of same card: **$0 (cached!)**
- Second listen to reading: **$0 (cached!)**

**Estimated cost reduction: 60-80% for typical usage patterns**

---

## Voice Characteristics

| Voice | Personality | Best For |
|-------|-------------|----------|
| **nova** â­ | Warm, mystical, contemplative | Tarot readings, spiritual guidance (DEFAULT) |
| **shimmer** | Ethereal, gentle, soft | Alternative mystical voice, gentler tone |
| **alloy** | Balanced, professional, neutral | Informative content, neutral narration |
| **echo** | Clear, articulate, steady | Precise delivery, structured content |
| **fable** | Expressive, storytelling | Dramatic readings, narrative emphasis |
| **onyx** | Deep, resonant, authoritative | Grounding presence, serious topics |

---

## Instruction Template Design Principles

Based on gpt-4o-mini-tts capabilities, effective instructions:

âœ… **DO:**
- Specify delivery style ("speak gently," "use storytelling cadence")
- Define pacing ("pause briefly between," "speak slowly")
- Set emotional tone ("convey wisdom," "warm and inviting")
- Contextualize role ("as a tarot reader," "as a wise guide")
- Mention specific behaviors ("pause after card name")

âŒ **DON'T:**
- Request specific accents or languages (voice model handles language)
- Over-specify (model interprets naturally)
- Use contradictory instructions ("fast but contemplative")

---

## Future Enhancement Opportunities

### 1. **User Voice Preferences**
Add to `SettingsToggles.jsx`:
```javascript
<select onChange={(e) => setPreferredVoice(e.target.value)}>
  <option value="nova">Nova (Warm & Mystical)</option>
  <option value="shimmer">Shimmer (Ethereal)</option>
  {/* ... */}
</select>
```

### 2. **Dynamic Speed Control**
```javascript
<input
  type="range"
  min="0.8"
  max="1.2"
  step="0.05"
  value={speechSpeed}
  onChange={(e) => setSpeechSpeed(e.target.value)}
/>
```

### 3. **Context Auto-Detection**
```javascript
function detectContext(text) {
  if (text.length < 100) return 'card-reveal';
  if (text.includes('synthesis') || text.includes('guidance')) return 'synthesis';
  return 'full-reading';
}
```

### 4. **Streaming Audio**
For very long readings, implement streaming to start playback before full generation completes.

### 5. **Background Queue**
Pre-generate and cache readings in background based on user behavior patterns.

---

## Testing Checklist

Before deployment with Azure OpenAI API key:

- [ ] Set environment variables in Cloudflare Pages
- [ ] Test card reveal narration (short, reverent tone)
- [ ] Test full reading narration (contemplative, flowing)
- [ ] Verify caching works (second play is instant)
- [ ] Test cache eviction (localStorage limits)
- [ ] Test fallback waveform (when API unavailable)
- [ ] Verify cost tracking in Azure portal
- [ ] Test voice selection (nova, shimmer)
- [ ] Test with slow network (loading states)
- [ ] Test with localStorage disabled (graceful degradation)

---

## Deployment Steps

### 1. **Azure OpenAI Setup**

```bash
# Create Azure OpenAI resource (if not existing)
az cognitiveservices account create \
  --name mystic-tarot-openai \
  --resource-group your-rg \
  --kind OpenAI \
  --sku S0 \
  --location eastus2  # gpt-4o-mini-tts region

# Deploy gpt-4o-mini-tts model
# (Use Azure Portal: Deployments â†’ Create â†’ gpt-4o-mini-tts)
```

### 2. **Get Credentials**

```bash
# Get endpoint
az cognitiveservices account show \
  --name mystic-tarot-openai \
  --resource-group your-rg \
  --query "properties.endpoint" --output tsv

# Get API key
az cognitiveservices account keys list \
  --name mystic-tarot-openai \
  --resource-group your-rg \
  --query "key1" --output tsv
```

### 3. **Configure Cloudflare Pages**

In Cloudflare Pages dashboard â†’ Settings â†’ Environment variables:

```
AZURE_OPENAI_ENDPOINT = https://mystic-tarot-openai.openai.azure.com
AZURE_OPENAI_API_KEY = your-key-here
AZURE_OPENAI_GPT_AUDIO_MINI_DEPLOYMENT = gpt-4o-mini-tts
```

### 4. **Deploy**

```bash
npm run build
npm run deploy
```

---

## Troubleshooting

### Issue: "Azure gpt-4o-mini-tts error 404"
- **Cause**: Deployment name mismatch
- **Fix**: Verify `AZURE_OPENAI_GPT_AUDIO_MINI_DEPLOYMENT` matches Azure portal deployment name

### Issue: "No audio field in TTS response"
- **Cause**: API error, falling back to waveform
- **Fix**: Check Cloudflare Pages logs, verify env vars, check Azure quota

### Issue: localStorage quota exceeded
- **Cause**: Too many cached audio files
- **Fix**: Cache eviction should handle this automatically; verify eviction logic
- **Manual**: `localStorage.clear()` or clear `tts_cache_*` keys

### Issue: Audio doesn't play
- **Cause**: Browser autoplay policy
- **Fix**: User must interact with page first (click button); this is by design

### Issue: Slow playback on first reveal
- **Cause**: API latency (~1-3 seconds for generation)
- **Fix**: This is expected; subsequent plays are instant (cached)

---

## Monitoring & Optimization

### Cost Monitoring

Track in Azure Portal:
- Cognitive Services â†’ Metrics â†’ Total Calls
- Cost Management â†’ Cost by Service

### Performance Monitoring

Log metrics in `tts.js`:
```javascript
console.log('TTS generation time:', Date.now() - startTime, 'ms');
console.log('Cache hit:', !!cachedAudio);
```

### Optimization Tips

1. **Pre-cache common content**
   - Standard card meanings
   - Welcome messages
   - Common synthesis phrases

2. **Adjust cache limits**
   - Increase to 100 items for power users
   - Monitor localStorage usage

3. **Batch API calls** (future)
   - Generate all 10 Celtic Cross card reveals in one batch
   - Requires API enhancement

---

## Conclusion

The gpt-4o-mini-tts integration transforms Mystic Tarot's voice experience from generic TTS to **context-aware, mystically-delivered tarot narration**. The steerable instructions feature ensures each reading context (card reveal, full reading, synthesis) has appropriate tone, pacing, and emotional delivery.

Combined with intelligent caching, this provides:
- âœ… Professional, contemplative narration
- âœ… 60-80% cost reduction through caching
- âœ… Instant playback for repeated content
- âœ… Graceful degradation when API unavailable
- âœ… Scalable, production-ready architecture

**Estimated monthly cost for 1000 readings: $45-90** (vs $150-300 without caching) ğŸ¯
